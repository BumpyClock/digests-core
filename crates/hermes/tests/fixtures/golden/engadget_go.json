{
  "url": "https://www.engadget.com/wearables/heres-how-google-is-laying-the-foundation-for-our-mixed-reality-future-180000716.html",
  "title": "Here's how Google is laying the foundation for our mixed reality future",
  "content": "\u003cp class=\"col-body mb-4 leading-7 text-[18px] md:leading-8 break-words min-w-0 charcoal-color\"\u003eToday, during the \u003ca class=\"link \"\u003eXR edition of The Android Show\u003c/a\u003e, Google showed off a bunch of updates and new features headed to its mixed reality OS. And while most of the news was aimed at developers, I got a chance to demo some of the platform\u0026#39;s expanded capabilities on a range of hardware including \u003ca class=\"link \"\u003eSamsung\u0026#39;s Galaxy XR headset\u003c/a\u003e, two different reference designs and an early version of \u003ca class=\"link \"\u003eXreal\u0026#39;s Project Aura smart glasses\u003c/a\u003e and I came away rather impressed. So here\u0026#39;s a rundown of what I saw and how it will impact the rapidly growing ecosystem of head-mounted displays.\u003c/p\u003e\u003cp class=\"col-body mb-4 leading-7 text-[18px] md:leading-8 break-words min-w-0 charcoal-color\"\u003eFirst up was one of Google\u0026#39;s reference design smart glasses with a single waveguide RGB display built into its right lens. I\u0026#39;ve included a picture of it here, but try not to read too deeply into its design or aesthetics, as this device is meant to be a testbed for Android XR features and not an early look at upcoming models.\u003c/p\u003e\u003cdiv class=\"relative\"\u003e\u003cimg alt=\"Try not to read too much into the appearance of Google\u0026#39;s reference design smart glasses, as they are explicitly labeled as prototypes meant to test upcoming features in Android XR.\" width=\"960\" height=\"576\" class=\"fig-image-round\"/\u003e\u003cspan class=\"absolute bottom-0 right-0 rounded-full bg-white p-3 opacity-100 shadow-elevation-3 transition-opacity duration-300 group-hover:block group-hover:opacity-100 md:p-[17px] lg:bottom-6 lg:right-6 lg:bg-white/90 lg:p-5 lg:opacity-0 lg:shadow-none\"\u003e\u003c/span\u003e\u003c/div\u003e\u003cdiv\u003e\u003cspan class=\"[\u0026amp;_p]:inline\"\u003eTry not to read too much into the appearance of Google\u0026#39;s reference design smart glasses, as they are explicitly labeled as prototypes meant to test upcoming features in Android XR.\u003c/span\u003e\u003cspan\u003e (Sam Rutherford for Engadget)\u003c/span\u003e\u003c/div\u003e\u003cp class=\"col-body mb-4 leading-7 text-[18px] md:leading-8 break-words min-w-0 charcoal-color\"\u003eAfter putting them on, I was able to ask Gemini to play some tunes on YouTube Music before answering a call simply by tapping on the touchpad built into the right side of the frames. And because the reference model also had onboard world-facing cameras, I could easily share my view with the person on the other end of the line.\u003c/p\u003e\u003cdiv class=\"col-fullbleed mb-4 bg-marshmallow pb-5 dark:bg-ramones md:invisible md:mb-0 md:h-0 md:overflow-hidden md:pb-0\"\u003e\u003cdiv class=\"py-2 text-center text-xs uppercase\"\u003eAdvertisement\u003c/div\u003e\u003cdiv class=\"flex w-full flex-nowrap justify-center\"\u003e\u003cdiv class=\"flex\" id=\"_R_25eb6tialuknpfmlbH1_\"\u003e\u003cdiv class=\"hidden\" id=\"_R_25eb6tialuknpfmlb_\"\u003e\u003c/div\u003e\u003cdiv class=\"flex size-full items-center justify-center bg-marshmallow text-center leading-3\"\u003eAdvertisement\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cp class=\"col-body mb-4 leading-7 text-[18px] md:leading-8 break-words min-w-0 charcoal-color\"\u003eNaturally, I was curious about how glasses had the bandwidth to do all this, because in normal use, they rely on a Bluetooth or Bluetooth LE connection. When asked, Max Spear, Group Product Manager for XR, shared that depending on the situation, the device can seamlessly switch between both Bluetooth and Wi-Fi, which was rather impressive because I couldn\u0026#39;t even detect when that transition happened. Spear also noted that one of Google\u0026#39;s focuses for Android XR is making it easier for developers to port over the apps people already know and love.\u003c/p\u003e\u003cp class=\"col-body mb-4 leading-7 text-[18px] md:leading-8 break-words min-w-0 charcoal-color\"\u003eThis means for devices like the reference design I wore that feature a built-in display (or displays), the OS actually uses the same code meant for standard Android notifications (like quick replies) to create a minimalist UI instead of forcing app makers to update each piece of software to be compliant with an ever-increasing number of devices. Alternatively, for models that are super lightweight and rely strictly on speakers (like \u003ca class=\"link \"\u003eBose Frames\u003c/a\u003e), Google has also designed Android XR so that you only need mics and voice controls to access a wide variety of apps without the need for visual menus.\u003c/p\u003e\u003cdiv class=\"relative\"\u003e\u003cimg alt=\"This is the picture Gemini created when I asked it to transform a picture of some pantry shelves into a sci-fi scene. \" width=\"896\" height=\"1200\" class=\"fig-image-round\"/\u003e\u003cspan class=\"absolute bottom-0 right-0 rounded-full bg-white p-3 opacity-100 shadow-elevation-3 transition-opacity duration-300 group-hover:block group-hover:opacity-100 md:p-[17px] lg:bottom-6 lg:right-6 lg:bg-white/90 lg:p-5 lg:opacity-0 lg:shadow-none\"\u003e\u003c/span\u003e\u003c/div\u003e\u003cdiv\u003e\u003cspan class=\"[\u0026amp;_p]:inline\"\u003eThis is the picture Google\u0026#39;s reference design smart glasses created (via Gemini ) when I asked it to transform a photo I took of some pantry shelves into a sci-fi kitchen.\u003c/span\u003e\u003cspan\u003e (Sam Rutherford for Engadget)\u003c/span\u003e\u003c/div\u003e\u003cp class=\"col-body mb-4 leading-7 text-[18px] md:leading-8 break-words min-w-0 charcoal-color\"\u003eMeanwhile, if you\u0026#39;re hoping to take photos with your smart glasses, there\u0026#39;s a surprising amount of capability there, too. Not only was I able to ask Gemini to take a photo, the glasses were also able to send a higher-res version to a connected smartwatch, which is super handy in case you want to review the image before moving on to the next shot. And when you want to inject some creativity, you can ask Gemini to transform pictures into practically anything you can imagine via \u003ca class=\"link \"\u003eNano Banana\u003c/a\u003e. In my case, I asked the AI to change a shot of a pantry into a sci-fi kitchen and Gemini delivered with aplomb, including converting the room into a metal-clad setting complete with lots of light strips and a few bursts of steam.\u003c/p\u003e\u003cp class=\"col-body mb-4 leading-7 text-[18px] md:leading-8 break-words min-w-0 charcoal-color\"\u003eHowever, one of the most impressive demos was when I asked Google\u0026#39;s reference glasses to look at some of that same pantry environment and then use the ingredients to create a recipe based on my specifications (no tomatoes please, my wife isn\u0026#39;t a fan). Gemini went down an Italian route by picking pasta, jarred banana peppers, bell peppers (which I thought was a somewhat unusual combination) and more, before launching into the first steps of the recipe. Sadly, I didn\u0026#39;t have time to actually cook it, but as part of the demo, I learned that Gemini has been trained to understand human-centric gestures like pointing and picking things up. This allows it to better understand context without the need to be super specific, which is one of those little but very impactful tricks that allows AI to feel way less robotic.\u003c/p\u003e\u003cdiv class=\"relative\"\u003e\u003cimg alt=\"This is how Google Maps will look on Android XR. However, it\u0026#39;s important to note that this is the flat 2D version instead of the more detailed stereoscopic view available on smart glasses with dual displays. \" width=\"960\" height=\"538\" class=\"fig-image-round\"/\u003e\u003cspan class=\"absolute bottom-0 right-0 rounded-full bg-white p-3 opacity-100 shadow-elevation-3 transition-opacity duration-300 group-hover:block group-hover:opacity-100 md:p-[17px] lg:bottom-6 lg:right-6 lg:bg-white/90 lg:p-5 lg:opacity-0 lg:shadow-none\"\u003e\u003c/span\u003e\u003c/div\u003e\u003cdiv\u003e\u003cspan class=\"[\u0026amp;_p]:inline\"\u003eThis is how Google Maps will look on Android XR. Note that this is the flat 2D version instead of the more detailed stereoscopic view available on smart glasses with dual displays.\u003c/span\u003e\u003cspan\u003e (Sam Rutherford for Engadget)\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\"col-fullbleed mb-4 bg-marshmallow pb-5 dark:bg-ramones md:invisible md:mb-0 md:h-0 md:overflow-hidden md:pb-0\"\u003e\u003cdiv class=\"py-2 text-center text-xs uppercase\"\u003eAdvertisement\u003c/div\u003e\u003cdiv class=\"flex w-full flex-nowrap justify-center\"\u003e\u003cdiv class=\"flex\" id=\"_R_2deb6tialuknpfmlbH1_\"\u003e\u003cdiv class=\"hidden\" id=\"_R_2deb6tialuknpfmlb_\"\u003e\u003c/div\u003e\u003cdiv class=\"flex size-full items-center justify-center bg-marshmallow text-center leading-3\"\u003eAdvertisement\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cp class=\"col-body mb-4 leading-7 text-[18px] md:leading-8 break-words min-w-0 charcoal-color\"\u003eThen I had a chance to see how Uber and Google Maps ran on the reference glasses, this time using models with both single and dual RGB displays. Surprisingly, even on the monocular version, Maps was able to generate a detailed map with the ability to zoom in and out. But when I switched over to the binocular model, I noticed a significant jump in sharpness and clarity along with a higher-fidelity map with stereoscopic 3D images of buildings. Now, it may be a bit early to call this, and the perception of sharpness varies greatly between people based on their head shape and other factors, but after seeing that, I\u0026#39;m even more convinced that the smart glasses with dual RGB displays are what the industry will settle on in the long term.\u003c/p\u003e\u003cp class=\"col-body mb-4 leading-7 text-[18px] md:leading-8 break-words min-w-0 charcoal-color\"\u003eThe second type of device I used was the \u003ca class=\"link \"\u003eSamsung Galaxy XR\u003c/a\u003e, which I originally tried out when it was announced back in October. However, in the short time since, Google has cooked up a few new features that really help expand the headset\u0026#39;s capabilities. By using the goggle\u0026#39;s exterior-facing cameras, I was able to play a game of I Spy with Gemini. Admittedly, this might sound like a small addition, but I think it\u0026#39;s going to play a big part in how we use devices running Android XR, because it allows the headset (or glasses) to understand better what you\u0026#39;re looking at in order to provide more helpful contextual responses.\u003c/p\u003e\u003cdiv class=\"relative\"\u003e\u003cimg alt=\"Even though it was announced not long ago in late October, Samsung\u0026#39;s Galaxy XR headset is already getting some new features thanks to some updates coming to Android XR. \" width=\"960\" height=\"576\" class=\"fig-image-round\"/\u003e\u003cspan class=\"absolute bottom-0 right-0 rounded-full bg-white p-3 opacity-100 shadow-elevation-3 transition-opacity duration-300 group-hover:block group-hover:opacity-100 md:p-[17px] lg:bottom-6 lg:right-6 lg:bg-white/90 lg:p-5 lg:opacity-0 lg:shadow-none\"\u003e\u003c/span\u003e\u003c/div\u003e\u003cdiv\u003e\u003cspan class=\"[\u0026amp;_p]:inline\"\u003eEven though it was announced not long ago in late October, Samsung\u0026#39;s Galaxy XR headset is already getting some new features thanks to some updates coming to Android XR.\u003c/span\u003e\u003cspan\u003e (Sam Rutherford for Engadget)\u003c/span\u003e\u003c/div\u003e\u003cp class=\"col-body mb-4 leading-7 text-[18px] md:leading-8 break-words min-w-0 charcoal-color\"\u003eHowever, the biggest surprise was when I joined a virtual call with someone using one of Google\u0026#39;s new avatars, called Likeness. Instead of the \u003ca class=\"link \"\u003elow-polygon cartoony characters\u003c/a\u003e we\u0026#39;ve seen before in places like Meta Horizon, Google\u0026#39;s virtual representations of people\u0026#39;s faces are almost scary good. So good I had to double-check that they weren\u0026#39;t real and from what I\u0026#39;ve seen they\u0026#39;re even a step up from Apple\u0026#39;s Personas. Google says that headsets like the Galaxy XR rely on interior sensors to track and respond to facial movements, while users will be able to create and edit their avatars using a standalone app due out sometime next year.\u003c/p\u003e\u003cdiv class=\"relative\"\u003e\u003cimg alt=\"The person in the bottom right is using a Likeness, which during my demo looked surprisingly responsive and realistic. \" width=\"960\" height=\"577\" class=\"fig-image-round\"/\u003e\u003cspan class=\"absolute bottom-0 right-0 rounded-full bg-white p-3 opacity-100 shadow-elevation-3 transition-opacity duration-300 group-hover:block group-hover:opacity-100 md:p-[17px] lg:bottom-6 lg:right-6 lg:bg-white/90 lg:p-5 lg:opacity-0 lg:shadow-none\"\u003e\u003c/span\u003e\u003c/div\u003e\u003cdiv\u003e\u003cspan class=\"[\u0026amp;_p]:inline\"\u003eThe person in the bottom right is using a Likeness, which during my demo looked surprisingly responsive and realistic.\u003c/span\u003e\u003cspan\u003e (Google)\u003c/span\u003e\u003c/div\u003e\u003cp class=\"col-body mb-4 leading-7 text-[18px] md:leading-8 break-words min-w-0 charcoal-color\"\u003eNext, I got a chance to test out the Android XR\u0026#39;s PC connectivity by playing \u003cem\u003eStray\u003c/em\u003e on the Galaxy XR while it was tethered wirelessly to a nearby laptop. Not only did it run almost flawlessly with low latency, I was also able to use a paired controller instead of relying on hand-tracking or the laptop\u0026#39;s mouse and keyboard. This is something I\u0026#39;ve been eagerly waiting to try because it feels like Google has put a lot of work into making Android XR devices play nicely with other devices and OSes. Initially, you\u0026#39;ll only be able to connect Windows PCs to the Galaxy XR, but Google says it\u0026#39;s looking to support macOS systems as well.\u003c/p\u003e\u003cdiv class=\"col-fullbleed mb-4 bg-marshmallow pb-5 dark:bg-ramones md:invisible md:mb-0 md:h-0 md:overflow-hidden md:pb-0\"\u003e\u003cdiv class=\"py-2 text-center text-xs uppercase\"\u003eAdvertisement\u003c/div\u003e\u003cdiv class=\"flex w-full flex-nowrap justify-center\"\u003e\u003cdiv class=\"flex\" id=\"_R_2keb6tialuknpfmlbH1_\"\u003e\u003cdiv class=\"hidden\" id=\"_R_2keb6tialuknpfmlb_\"\u003e\u003c/div\u003e\u003cdiv class=\"flex size-full items-center justify-center bg-marshmallow text-center leading-3\"\u003eAdvertisement\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cp class=\"col-body mb-4 leading-7 text-[18px] md:leading-8 break-words min-w-0 charcoal-color\"\u003eFinally, I got to try out Xreal\u0026#39;s Project Aura glasses to see how Android XR works on a device primarily designed to give you big virtual displays in a portable form factor. Unfortunately, because this was a pre-production unit, I wasn\u0026#39;t able to take photos. That said, as far as the glasses go, I was really impressed with their resolution and sharpness and the inclusion of electrochromic glass is a really nice touch, as it allows users to change how heavily the lenses are tinted with a single touch. Alternatively, the glasses can also adjust the tint automatically based on whatever app you are using to give you a more or less isolated atmosphere, depending on the situation. I also appreciate the Aura\u0026#39;s increased 70-degree FOV, but if I\u0026#39;m nitpicking, I wish it were a bit higher, as I occasionally found myself wanting a bit more vertical display area.\u003c/p\u003e\u003cdiv class=\"relative\"\u003e\u003cimg alt=\"Unfortunately, I wasn\u0026#39;t allowed to take photos of Xreal\u0026#39;s Project Aura smart glasses, as the model I used was still an early pre-production unit. So here\u0026#39;s a shot provided by Google instead. \" width=\"960\" height=\"640\" class=\"fig-image-round\"/\u003e\u003cspan class=\"absolute bottom-0 right-0 rounded-full bg-white p-3 opacity-100 shadow-elevation-3 transition-opacity duration-300 group-hover:block group-hover:opacity-100 md:p-[17px] lg:bottom-6 lg:right-6 lg:bg-white/90 lg:p-5 lg:opacity-0 lg:shadow-none\"\u003e\u003c/span\u003e\u003c/div\u003e\u003cdiv\u003e\u003cspan class=\"[\u0026amp;_p]:inline\"\u003eUnfortunately, I wasn\u0026#39;t allowed to take photos of Xreal\u0026#39;s Project Aura smart glasses, as the model I used was still an early pre-production unit. So here\u0026#39;s a shot provided by Google instead.\u003c/span\u003e\u003cspan\u003e (Google / Xreal)\u003c/span\u003e\u003c/div\u003e\u003cp class=\"col-body mb-4 leading-7 text-[18px] md:leading-8 break-words min-w-0 charcoal-color\"\u003eAs a device that\u0026#39;s sort of between lightweight smart glasses and a full VR headset, the Aura relies on a wired battery pack that also doubles as a touchpad and a hub for plugging in external devices like your phone, laptop or even game consoles.\u003c/p\u003e\u003cp class=\"col-body mb-4 leading-7 text-[18px] md:leading-8 break-words min-w-0 charcoal-color\"\u003eWhile using the Aura, I was able to connect to a different PC and multitask in style, as the glasses were able to support multiple virtual displays while running several different apps at the same time. This allowed me to be on a virtual call with someone using a Likeness while I had two other virtual windows open on either side. I also played an AR game (\u003ca class=\"link \"\u003eDemeo\u003c/a\u003e) while I moved around in virtual space and used my hands to reposition the battlefield or pick up objects with my hands.\u003c/p\u003e\u003cp class=\"col-body mb-4 leading-7 text-[18px] md:leading-8 break-words min-w-0 charcoal-color\"\u003eNow I will fully admit this is a lot and it took me a bit to process everything. But upon reflection, I have a few takeaways from my time with the various Android XR devices and prototypes. More than any other headset or smart glasses platform out now, it feels like Google is doing a ton to embrace a growing ecosystem of devices. That\u0026#39;s really important because we\u0026#39;re still so early in the lifecycle for wearable gadgets with displays that no one has really figured out a truly polished design like we have for smartphones and laptops. And until we get there, this means that a highly adaptable OS will go a long way towards supporting OEMs like Samsung, Xreal and others.\u003c/p\u003e\u003cdiv class=\"col-fullbleed mb-4 bg-marshmallow pb-5 dark:bg-ramones md:invisible md:mb-0 md:h-0 md:overflow-hidden md:pb-0\"\u003e\u003cdiv class=\"py-2 text-center text-xs uppercase\"\u003eAdvertisement\u003c/div\u003e\u003cdiv class=\"flex w-full flex-nowrap justify-center\"\u003e\u003cdiv class=\"flex\" id=\"_R_2qeb6tialuknpfmlbH1_\"\u003e\u003cdiv class=\"hidden\" id=\"_R_2qeb6tialuknpfmlb_\"\u003e\u003c/div\u003e\u003cdiv class=\"flex size-full items-center justify-center bg-marshmallow text-center leading-3\"\u003eAdvertisement\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cp class=\"col-body mb-4 leading-7 text-[18px] md:leading-8 break-words min-w-0 charcoal-color\"\u003eBut that\u0026#39;s not all. It\u0026#39;s clear Google is focused on making Android XR devices easy to build for. That\u0026#39;s because the company knows that without useful software that can highlight the components and features coming on next-gen spectacles, there\u0026#39;s a chance that interest will remain rather niche — similar to what we\u0026#39;ve seen when looking at the adoption of VR headsets. So in a way, Google is waging a battle on two fronts, which makes navigating uncharted waters that much more difficult.\u003c/p\u003e\u003cdiv class=\"relative\"\u003e\u003cimg alt=\"A major focus for Android XR while people are still figuring out how to make smart glasses is to support a wide variety of designs including those with single displays, dual displays or models without any displays that rely on cameras and speakers. \" width=\"960\" height=\"576\" class=\"fig-image-round\"/\u003e\u003cspan class=\"absolute bottom-0 right-0 rounded-full bg-white p-3 opacity-100 shadow-elevation-3 transition-opacity duration-300 group-hover:block group-hover:opacity-100 md:p-[17px] lg:bottom-6 lg:right-6 lg:bg-white/90 lg:p-5 lg:opacity-0 lg:shadow-none\"\u003e\u003c/span\u003e\u003c/div\u003e\u003cdiv\u003e\u003cspan class=\"[\u0026amp;_p]:inline\"\u003eA major focus for Android XR while people are still figuring out how to make smart glasses is to support a wide variety of designs including those with single displays, dual displays or models without any displays that rely on cameras and speakers.\u003c/span\u003e\u003cspan\u003e (Sam Rutherford for Engadget)\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\"col-fullbleed mb-4 bg-marshmallow pb-5 dark:bg-ramones md:invisible md:mb-0 md:h-0 md:overflow-hidden md:pb-0\"\u003e\u003cdiv class=\"py-2 text-center text-xs uppercase\"\u003eAdvertisement\u003c/div\u003e\u003cdiv class=\"flex w-full flex-nowrap justify-center\"\u003e\u003cdiv class=\"flex\" id=\"_R_2teb6tialuknpfmlbH1_\"\u003e\u003cdiv class=\"hidden\" id=\"_R_2teb6tialuknpfmlb_\"\u003e\u003c/div\u003e\u003cdiv class=\"flex size-full items-center justify-center bg-marshmallow text-center leading-3\"\u003eAdvertisement\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cp class=\"col-body mb-4 leading-7 text-[18px] md:leading-8 break-words min-w-0 charcoal-color\"\u003eGoogle is putting a major emphasis on Android XR\u0026#39;s ability to serve as a framework for future gadgets and support and address developer needs. This mirrors the approach the company takes with regular Android and the opposite of Apple\u0026#39;s typical MO, because unlike the Vision Pro and \u003ca class=\"link \"\u003evisionOS\u003c/a\u003e, it appears Google is going to rely heavily on its partners like Xreal, Warby Parker, Gentle Monster and others to create engaging hardware. Furthermore, Google says it plans to support smart glasses that can be tethered to Android and iOS phones, as well as smartwatches from both ecosystems, though there will be some limitations for people using Apple devices due to inherent OS restrictions.\u003c/p\u003e\u003cp class=\"col-body mb-4 leading-7 text-[18px] md:leading-8 break-words min-w-0 charcoal-color\"\u003eThat\u0026#39;s not to say that there won\u0026#39;t be Pixel glasses sometime down the road, but at least for now, I think that\u0026#39;s a smart approach and possibly a lesson Google learned after releasing Google Glass over a decade ago. Meanwhile, hi-res and incredibly realistic avatars like Likenesses could be a turning point for virtual collaboration, because, in a first for me, talking to a digital representation of someone else felt kind of natural. After my demos, I had a chance to talk to Senior Director of Product Management for XR \u003ca class=\"link  rapid-with-clickid etailiffa-link\"\u003eJuston Payne\u003c/a\u003e, who highlighted the difference between smart glasses and typical gadgets by saying \u0026#34;Smart glasses have to be great glasses first. They need to have a good form factor, good lenses with prescription support, they need to look good and they have to be easy to buy.\u0026#34;\u003c/p\u003e\u003cp class=\"col-body mb-4 leading-7 text-[18px] md:leading-8 break-words min-w-0 charcoal-color\"\u003eThat\u0026#39;s no simple task and there\u0026#39;s no guarantee that next-gen smart glasses and headsets will be a grand slam. But from what I\u0026#39;ve seen, Google is building a very compelling foundation with Android XR.\u003c/p\u003e\u003cp class=\"col-body mb-4 leading-7 text-[18px] md:leading-8 break-words min-w-0 charcoal-color\"\u003e\u003cbr/\u003e\u003c/p\u003e",
  "date_published": "2025-12-08T18:00:00Z",
  "lead_image_url": "https://s.yimg.com/ny/api/res/1.2/J4kut_gh2ZWB3R.afOX4ow--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD03MjA-/https://d29szjachogqwa.cloudfront.net/images/user-uploaded/google-reference-design-lead.jpg",
  "domain": "www.engadget.com",
  "excerpt": "\u003cp class=\"col-body mb-4 leading-7 text-[18px] md:leading-8 break-words min-w-0 charcoal-color\"\u003eToday, during the \u003ca class=\"link \"\u003eXR edition of The Android Show\u003c/a\u003e, Google showed off a bunch of updates and new features headed to its mixed reality OS. And while most of the news was aimed at developers, I got a chance to demo some of the platform\u0026#39;s expanded capabilities on a range of hardware including \u003ca class=\"link \"\u003eSamsung\u0026#39;s Galaxy XR headset\u003c/a\u003e, two different reference designs and an early version of \u003ca class=\"link \"\u003eXreal\u0026#39;s Project Aura smart glasses\u003c/a\u003e and I came away rather impressed. So here\u0026#39;s a rundown of what I saw and how it will impact the rapidly growing ecosystem of head-mounted displays.\u003c/p\u003e\u003cp class=\"col-body mb-4 leading-7 text-[18px] md:leading-8 break-words min-w-0 charcoal-color\"\u003eFirst up was one of Google\u0026#39;s reference design smart glasses with a single waveguide RGB display built into its right lens. I\u0026#39;ve included a picture of it here, but try not to read too deeply into its design or aesthetics, as this",
  "word_count": 2136,
  "site_name": "Engadget",
  "description": "Today at the Android Show: XR Edition, Google showed off a bunch of updates headed to its recently released mixed reality platform. However, after demoing some of those features, I now have a much great appreciation for where Android XR is heading.",
  "language": "en-US",
  "favicon": "https://www.engadget.com/favicon.ico"
}
