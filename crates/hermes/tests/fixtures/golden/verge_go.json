{
  "url": "https://www.theverge.com/tech/839392/project-aura-android-xr-software-headsets-ai-glasses",
  "title": "A first look at Google’s Project Aura glasses built with Xreal",
  "content": "\u003cp class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph _1ymtmqpi _17nnmdy1 _17nnmdy0 _17nnmdy6 _17nnmdy5 _1xwtict1\"\u003eTeased at Google I/O, Project Aura is a collaboration between Xreal and Google. It’s the second Android XR device (the first being Samsung’s Galaxy XR headset) and is expected to launch in 2026. Putting it on, I get why the term “smart glasses” doesn’t exactly fit.\u003c/p\u003e\n\u003cp class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph _1ymtmqpi _17nnmdy1 _17nnmdy0 _1xwtict1\"\u003eIs it a headset? Smart glasses? Both? Those were the questions running through my head as I held Project Aura in my hands in a recent demo. It \u003cem\u003elooked\u003c/em\u003e like a pair of chunky sunglasses, except for the cord dangling off the left side, leading down to a battery pack that also served as a trackpad. When I asked, Google’s reps told me they consider it a headset masquerading as glasses. They have a term for it, too: wired XR glasses.\u003c/p\u003e\n\u003cp class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph _1ymtmqpi _17nnmdy1 _17nnmdy0 _1xwtict1\"\u003eI can connect wirelessly to a laptop and create a giant virtual desktop in my space. I have up to a 70-degree field of view. My first task is to launch Lightroom on the virtual desktop while opening YouTube in another window. I play a 3D tabletop game where I can pinch and pull the board to zoom in and out. I look at a painting on the wall and summon Circle to Search. Gemini tells me the name of the artwork and the artist.\u003c/p\u003e\n\u003cdiv class=\"duet--article--related _1ymtmqpj _1m6r73h0\"\u003e\u003ch3\u003eRelated\u003c/h3\u003e\u003cul\u003e\u003cli\u003e\u003ca class=\"_1m6r73h9\"\u003eXreal teases Project Aura smart glasses for Android XR\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca class=\"_1m6r73h9\"\u003eWe tried on Google’s prototype AI smart glasses\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca class=\"_1m6r73h9\"\u003eI saw Google’s plan to put Android on your face\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/div\u003e\n\u003cp class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph _1ymtmqpi _17nnmdy1 _17nnmdy0 _1xwtict1\"\u003eI’ve done all of this before in the Vision Pro and Galaxy XR. This time, my head \u003cem\u003eisn’t\u003c/em\u003e stuffed into a bulky headset. If I wore this in public, most people wouldn’t notice. But this isn’t augmented reality, which overlays digital information over the real world. It’s much more like using a Galaxy XR, where you see apps in front of you and your surroundings.\u003c/p\u003e\n\u003cp class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph _1ymtmqpi _17nnmdy1 _17nnmdy0 _1xwtict1\"\u003eA Google representative told me everything I tried on Project Aura had originally been developed for Galaxy XR. None of the apps, features, or experiences had to be remade for Project Aura’s form factor. That’s huge.\u003c/p\u003e\n\n\u003cp class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph _1ymtmqpi _17nnmdy1 _17nnmdy0 _17nnmdy6 _17nnmdy5 _1xwtict1\"\u003eXR has a major app problem. Take the Meta Ray-Ban Display and the Vision Pro. Both launched with few third-party apps, giving consumers little reason to wear them. Developers also have to pick and choose which of these gadgets they’ll invest in making apps for. That leaves little room for smaller companies with big ideas to compete or experiment.\u003c/p\u003e\n\u003cp class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph _1ymtmqpi _17nnmdy1 _17nnmdy0 _1xwtict1\"\u003eThat’s what makes Android XR fascinating. Smaller players, like Xreal, can access apps developed for Samsung’s headset. Android apps will also work on the AI glasses launching next year from Warby Parker and Gentle Monster.\u003c/p\u003e\n\u003cp class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph _1ymtmqpi _17nnmdy1 _17nnmdy0 _1xwtict1\"\u003e“I think this is probably the best thing for all the developers. You just don’t see any fragmentation anymore. And I do believe there will be more and more devices converging together. That’s the whole point of Android XR,” says Xreal CEO Chi Xu.\u003c/p\u003e\n\u003cdiv\u003e\u003cdiv class=\"_1ymtmqpj\"\u003e\u003cdiv class=\"\"\u003e\u003cdiv class=\"duet--media--content-warning ucljxw0\"\u003e\u003cdiv class=\"duet--article--image-gallery-image kqz8fh0 _1ymtmqpx\" id=\"dmcyOmltYWdlOjY3MTE0Mg==\"\u003e\u003ca class=\"kqz8fh1\"\u003e\u003cimg alt=\"Close up of Google’s Prototype AI glasses from a side angle at Google I/O. In the background you can see a smartphone and vase with plants.\" class=\"x271pn0\" sizes=\"(max-width: 639px) 100vw, (max-width: 1023px) 50vw, 700px\" srcset=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/05/DSC01196.jpg?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0.11005135730007%2C100%2C99.7798972854\u0026amp;w=256 256w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/05/DSC01196.jpg?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0.11005135730007%2C100%2C99.7798972854\u0026amp;w=376 376w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/05/DSC01196.jpg?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0.11005135730007%2C100%2C99.7798972854\u0026amp;w=384 384w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/05/DSC01196.jpg?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0.11005135730007%2C100%2C99.7798972854\u0026amp;w=415 415w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/05/DSC01196.jpg?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0.11005135730007%2C100%2C99.7798972854\u0026amp;w=480 480w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/05/DSC01196.jpg?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0.11005135730007%2C100%2C99.7798972854\u0026amp;w=540 540w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/05/DSC01196.jpg?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0.11005135730007%2C100%2C99.7798972854\u0026amp;w=640 640w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/05/DSC01196.jpg?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0.11005135730007%2C100%2C99.7798972854\u0026amp;w=750 750w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/05/DSC01196.jpg?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0.11005135730007%2C100%2C99.7798972854\u0026amp;w=828 828w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/05/DSC01196.jpg?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0.11005135730007%2C100%2C99.7798972854\u0026amp;w=1080 1080w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/05/DSC01196.jpg?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0.11005135730007%2C100%2C99.7798972854\u0026amp;w=1200 1200w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/05/DSC01196.jpg?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0.11005135730007%2C100%2C99.7798972854\u0026amp;w=1440 1440w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/05/DSC01196.jpg?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0.11005135730007%2C100%2C99.7798972854\u0026amp;w=1920 1920w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/05/DSC01196.jpg?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0.11005135730007%2C100%2C99.7798972854\u0026amp;w=2048 2048w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/05/DSC01196.jpg?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0.11005135730007%2C100%2C99.7798972854\u0026amp;w=2400 2400w\"/\u003e\u003c/a\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"duet--media--caption qama0i0\"\u003e\u003cem\u003eThis is a pair of Google’s AI glasses prototypes from Google I/O. The version I tried last week looked similar.\u003c/em\u003e Photo by Vjeran Pavic / The Verge\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\n\u003cp class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph _1ymtmqpi _17nnmdy1 _17nnmdy0 _1xwtict1\"\u003eSlipping on Google’s latest prototype AI glasses, I’m treated to an Uber demo in which a fictional version of me is hailing a ride from JFK Airport. A rep summons an Uber on the phone. I see an Uber widget pop up on the glasses display. It shows the estimated pickup time and my driver’s license plate and car model. If I look down, a map of the airport appears with real-time directions to the pickup zone.\u003c/p\u003e\n\u003cp class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph _1ymtmqpi _17nnmdy1 _17nnmdy0 _1xwtict1\"\u003eIt’s all powered by Uber’s Android app. Meaning Uber didn’t have to code an Android XR app from scratch. Theoretically, users could just pair the glasses and start using apps they already have.\u003c/p\u003e\n\u003cp class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph _1ymtmqpi _17nnmdy1 _17nnmdy0 _1xwtict1\"\u003eWhen I’m prompted to ask Gemini to play some music, a YouTube Music widget pops up, showing the title of a funky jazz mix and media controls. It’s also just using the YouTube Music app on an Android phone.\u003c/p\u003e\n\u003cp class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph _1ymtmqpi _17nnmdy1 _17nnmdy0 _1xwtict1\"\u003eI’m asked to tell Gemini to take a photo with the glasses. A preview of it appears in the display \u003cem\u003eand\u003c/em\u003e on a paired Pixel Watch. The idea is that integrating smartwatches gives users more options. Say someone wants audio-only glasses with a camera. They can now take a picture and view what it looks like on the wrist. It’ll work on any compatible Wear OS watch.\u003c/p\u003e\n\u003cdiv\u003e\u003cdiv class=\"_1ymtmqpj\"\u003e\u003cdiv class=\"\"\u003e\u003cdiv class=\"duet--media--content-warning ucljxw0\"\u003e\u003cdiv class=\"duet--article--image-gallery-image kqz8fh0\" id=\"dmcyOmltYWdlOjgzOTY2NA==\"\u003e\u003ca class=\"kqz8fh1\"\u003e\u003cimg alt=\"Photos taken from Google’s AI glasses prototypes with K-pop-inspired effects overlaid. On the left side there’s a pantry lit in pink and blue neon lights; on the right, a person is swirled in neon effects, Korean lettering, and concert lighting.\" class=\"x271pn0\" sizes=\"(max-width: 639px) 100vw, (max-width: 1023px) 50vw, 700px\" srcset=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/image-1.png?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0%2C100%2C100\u0026amp;w=256 256w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/image-1.png?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0%2C100%2C100\u0026amp;w=376 376w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/image-1.png?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0%2C100%2C100\u0026amp;w=384 384w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/image-1.png?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0%2C100%2C100\u0026amp;w=415 415w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/image-1.png?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0%2C100%2C100\u0026amp;w=480 480w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/image-1.png?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0%2C100%2C100\u0026amp;w=540 540w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/image-1.png?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0%2C100%2C100\u0026amp;w=640 640w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/image-1.png?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0%2C100%2C100\u0026amp;w=750 750w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/image-1.png?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0%2C100%2C100\u0026amp;w=828 828w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/image-1.png?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0%2C100%2C100\u0026amp;w=1080 1080w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/image-1.png?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0%2C100%2C100\u0026amp;w=1200 1200w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/image-1.png?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0%2C100%2C100\u0026amp;w=1440 1440w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/image-1.png?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0%2C100%2C100\u0026amp;w=1920 1920w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/image-1.png?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0%2C100%2C100\u0026amp;w=2048 2048w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/image-1.png?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0%2C100%2C100\u0026amp;w=2400 2400w\"/\u003e\u003c/a\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"duet--media--caption qama0i0\"\u003e\u003cem\u003eNano Banana Pro added K-pop effects to a photo I took on Google’s AI prototype glasses. Not bad, though “future snacks” written on the left is in Japanese.\u003c/em\u003e Photo: Google\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\n\u003cp class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph _1ymtmqpi _17nnmdy1 _17nnmdy0 _1xwtict1\"\u003eI also try live translations where the glasses detect the language being spoken. I take Google Meet video calls. I get Nano Banana Pro to add K-pop elements to another photo I’ve taken. I try a second prototype with a display in both lenses, enabling a larger field of view. (These are \u003cem\u003enot\u003c/em\u003e coming out next year.) I watch a 3D YouTube video.\u003c/p\u003e\n\u003cp class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph _1ymtmqpi _17nnmdy1 _17nnmdy0 _1xwtict1\"\u003eIt’s all impressive. I hear a few spiels about how Gemini truly is the killer app. But my jaw really drops when I’m told next year’s Android XR glasses will support iOS.\u003c/p\u003e\n\u003cp class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph _1ymtmqpi _17nnmdy1 _17nnmdy0 _1xwtict1\"\u003e“The goal is to give this ability to have multimodal Gemini in your glasses to as many people as possible. If you’re an iPhone user and you have the Gemini app on your phone, great news. You’re gonna get the full Gemini experience there,” says Juston Payne, Google’s director of product management for XR.\u003c/p\u003e\n\u003cp class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph _1ymtmqpi _17nnmdy1 _17nnmdy0 _1xwtict1\"\u003ePayne notes that this will be broadly true across Google’s iOS apps, such as Google Maps and YouTube Music. The limitations on iOS will mostly involve third-party apps. But even there, Payne says the Android XR team is exploring workarounds. At a time when wearable ecosystem lock-in is at an all-time high, this is a breath of fresh air.\u003c/p\u003e\n\n\u003cp class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph _1ymtmqpi _17nnmdy1 _17nnmdy0 _17nnmdy6 _17nnmdy5 _1xwtict1\"\u003eGoogle’s use of its existing Android ecosystem is an astute move that could give Android XR an edge over Meta, which currently leads in hardware but has only \u003cem\u003ejust\u003c/em\u003e opened its API to developers. It also ramps up the pressure on Apple, which has fallen behind on both the AI and glasses fronts. Making things interoperable between device form factors? Frankly, it’s the only way an in-between device like Project Aura has a shot.\u003c/p\u003e\n\u003cp class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph _1ymtmqpi _17nnmdy1 _17nnmdy0 _1xwtict1\"\u003e“I know we can make these glasses smaller and smaller in the future, but we don’t have this ecosystem,” adds Xu, Xreal’s CEO. “There are only two companies right now in the world that can really have an ecosystem: Apple and Google. Apple, they’re not going to work with others. Google is the only option for us.”\u003c/p\u003e\n\u003cdiv class=\"_2ezt6b0\"\u003e\u003cdiv class=\"_1ozko3v3\"\u003e\u003c/div\u003e\u003c/div\u003e\n\u003cp class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph _1ymtmqpi _17nnmdy1 _17nnmdy0 _1xwtict1\"\u003eGoogle is trying to avoid past mistakes. It’s deliberately partnering with other companies to make the hardware. It’s steering clear of the conspicuous design of the original Google Glass. It has apps pre-launch. The prototypes explore multiple form factors — audio-only and displays in one or both lenses.\u003c/p\u003e\n\u003cp class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph _1ymtmqpi _17nnmdy1 _17nnmdy0 _1xwtict1\"\u003ePayne doesn’t dodge when I ask the big cultural question: How do you discourage glassholes?\u003c/p\u003e\n\u003cp class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph _1ymtmqpi _17nnmdy1 _17nnmdy0 _1xwtict1\"\u003e“There’s a very bright, pulsing light if anything’s being recorded. So if the sensor is on with the intent to save anything, it will tell everyone around,” says Payne. That includes queries to Gemini for \u003cem\u003eany \u003c/em\u003etask involving the camera. On and off switches will have clear red and green markings so users can prove to others that they’re not lying when they say the glasses aren’t recording. Payne says Android’s and Gemini’s existing permissions frameworks, privacy policies, encryption, data retention, and security guarantees will also apply.\u003c/p\u003e\n\u003cp class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph _1ymtmqpi _17nnmdy1 _17nnmdy0 _1xwtict1\"\u003e“There’s going to be a whole process for getting certain sensor access so we can avoid certain things that could happen if somebody decides to use the camera in a bad way,” Payne says, noting Google’s taking a conservative approach to granting third parties access to the cameras.\u003c/p\u003e\n\u003cp class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph _1ymtmqpi _17nnmdy1 _17nnmdy0 _17nnmdya _1xwtict1\"\u003eOn paper, Google is making smart moves that address many of the challenges inherent to this space. It sounds good, but that’s easy to say before these glasses launch. A lot could change between now and then.\u003c/p\u003e",
  "author": "Victoria Song",
  "date_published": "2025-12-08T18:00:00Z",
  "lead_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/Aura_4_TAS_XR_-Nov-06-2025_113.jpg?quality=90\u0026strip=all\u0026crop=0%2C10.732984293194%2C100%2C78.534031413613\u0026w=1200",
  "domain": "www.theverge.com",
  "excerpt": "\u003cp class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph _1ymtmqpi _17nnmdy1 _17nnmdy0 _17nnmdy6 _17nnmdy5 _1xwtict1\"\u003eTeased at Google I/O, Project Aura is a collaboration between Xreal and Google. It’s the second Android XR device (the first being Samsung’s Galaxy XR headset) and is expected to launch in 2026. Putting it on, I get why the term “smart glasses” doesn’t exactly fit.\u003c/p\u003e \u003cp class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph _1ymtmqpi _17nnmdy1 _17nnmdy0 _1xwtict1\"\u003eIs it a headset? Smart glasses? Both? Those were the questions running through my head as I held Project Aura in my hands in a recent demo. It \u003cem\u003elooked\u003c/em\u003e like a pair of chunky sunglasses, except for the cord dangling off the left side, leading down to a battery pack that also served as a trackpad. When I asked, Google’s reps told me they consider it a headset masquerading as glasses. They have a term for it, too: wired XR glasses.\u003c/p\u003e \u003cp class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph _1ymtmqpi _17nnmdy1 _17nnmdy0 _1xwtict1\"\u003eI can connect wirelessly to a laptop and create a giant virtual desktop",
  "word_count": 1323,
  "site_name": "The Verge",
  "description": "It’s the app ecosystem. Plus the fact that it’ll integrate with Wear OS watches and support iOS.",
  "language": "en-US",
  "favicon": "https://www.theverge.com/static-assets/icons/apple-touch-icon.png"
}
